{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 – Quantum Model Training\n",
    "\n",
    "Loads `X_selected.csv`, `y.csv`, scales, applies **BorderlineSMOTE**, reduces to **6 qubits** with PCA, trains **QVC** and **QSVM**, and pickles the models + preprocessing pipeline.\n",
    "\n",
    "**Inputs**  \n",
    "- `X_selected.csv`  \n",
    "- `y.csv`  \n",
    "- `selected_features.pkl`\n",
    "\n",
    "**Outputs**  \n",
    "- `qvc_model.pkl`  \n",
    "- `qsvm_model.pkl`  \n",
    "- `preprocessing_objects.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"qiskit==1.2.4\" \"qiskit-aer==0.15.1\" \"qiskit-machine-learning==0.7.2\" \"qiskit-algorithms==0.3.0\" imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, pickle, warnings, datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_machine_learning.algorithms import VQC\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "\n",
    "print(f\"Start: {datetime.datetime.now():%Y-%m-%d %H:%M:%S}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Load selected data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/content/drive/MyDrive/QuantumBoost2025/'\n",
    "X = pd.read_csv(base + 'X_selected.csv')\n",
    "y = pd.read_csv(base + 'y.csv').squeeze()\n",
    "with open(base + 'selected_features.pkl', 'rb') as f:\n",
    "    selected_features = pickle.load(f)\n",
    "print(f\"X shape: {X.shape}, selected: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Train-test split & scaling"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "robust = RobustScaler()\n",
    "X_train_r = robust.fit_transform(X_train)\n",
    "X_test_r  = robust.transform(X_test)\n",
    "\n",
    "mm = MinMaxScaler(feature_range=(0, 2*np.pi))\n",
    "X_train_q = mm.fit_transform(X_train_r)\n",
    "X_test_q  = mm.transform(X_test_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. BorderlineSMOTE + subset for quantum"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = BorderlineSMOTE(random_state=42, k_neighbors=5, kind='borderline-1')\n",
    "X_res, y_res = sm.fit_resample(X_train_q, y_train)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, train_size=0.7, random_state=42)\n",
    "for tr, _ in sss.split(X_res, y_res):\n",
    "    X_q = X_res[tr]\n",
    "    y_q = y_res[tr]\n",
    "print(f\"Quantum training subset: {X_q.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. PCA → 6 qubits"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 6\n",
    "pca = PCA(n_components=n_qubits, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_q)\n",
    "X_test_pca  = pca.transform(X_test_q)\n",
    "\n",
    "pca_scaler = MinMaxScaler(feature_range=(0, 2*np.pi))\n",
    "X_train_pca = pca_scaler.fit_transform(X_train_pca)\n",
    "X_test_pca  = pca_scaler.transform(X_test_pca)\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Quantum circuits"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = ZZFeatureMap(feature_dimension=n_qubits, reps=3, entanglement='full')\n",
    "ansatz      = TwoLocal(n_qubits, ['ry','rz'], 'cx', entanglement='full', reps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. QVC training"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler   = Sampler()\n",
    "optimizer = COBYLA(maxiter=50)\n",
    "\n",
    "qvc = VQC(sampler=sampler, feature_map=feature_map, ansatz=ansatz, optimizer=optimizer)\n",
    "qvc.fit(X_train_pca[:500], y_q[:500])   # limit for demo speed\n",
    "print(\"QVC trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7. QSVM training"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "qsvm   = QSVC(quantum_kernel=kernel)\n",
    "qsvm.fit(X_train_pca[:500], y_q[:500])\n",
    "print(\"QSVM trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 8. Save everything"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = '/content/drive/MyDrive/QuantumBoost2025/'\n",
    "with open(out+'qvc_model.pkl','wb') as f:   pickle.dump(qvc, f)\n",
    "with open(out+'qsvm_model.pkl','wb') as f:  pickle.dump(qsvm, f)\n",
    "\n",
    "prep = {'robust':robust, 'minmax':mm, 'pca':pca, 'pca_scaler':pca_scaler,\n",
    "        'features':selected_features}\n",
    "with open(out+'preprocessing_objects.pkl','wb') as f: pickle.dump(prep, f)\n",
    "print(\"All artefacts saved.\")"
   ]
  }
 ],
 "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3"}},
 "nbformat": 4,
 "nbformat_minor": 2
}